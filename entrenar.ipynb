{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasifica una imagen entre tres consolas de videojuegos. \n",
    "\n",
    "Estructura de carpetas del proyecto\n",
    "\n",
    "```\n",
    "Clasificador/\n",
    "├── data/                 Almacena los datos necesario del proyecto\n",
    "|   ├── entrenamiento/    Almacena las imagenes de entrenamiento\n",
    "|   |   ├── Opcion1/      Almacena imágenes de la opcion1\n",
    "|   |   ├── Opcion2/      Almacena imágenes de la opcion2\n",
    "|   |   └── Opcion3/      Almacena imágenes de la opcion3\n",
    "|   └── validacion/       Almacena las imagenes de validación\n",
    "|       ├── Opcion1/      Almacena imágenes de la opcion1\n",
    "|       ├── Opcion2/      Almacena imágenes de la opcion2\n",
    "|       └── Opcion3/      Almacena imágenes de la opcion3\n",
    "├── cnn.ipynb             \n",
    "├── entrenar.ipynb        Contendrá la Red nerual y se entrenará\n",
    "└── predecir.ipynb        Cargar el modelo y generar la predicción\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libreria para movernos en el sistema operativo\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "# Ayuda a preprocesar las imagenes que le daremos al algoritmo\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Optimizador con el que entrenaremos al algoritmo\n",
    "from tensorflow.python.keras import optimizers\n",
    "\n",
    "# Permite hacer redes neurales secuenciales\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "\n",
    "# \n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
    "\n",
    "# Capas en las que trabajaremos las capas de convoluciones y maxPooling\n",
    "from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "# Matar sesión existente de keras para entrenar desde 0\n",
    "from tensorflow.python.keras import backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matar sesión existente de keras para entrenar desde 0\n",
    "k.clear_session()\n",
    "\n",
    "# Directorios de los datos a usar\n",
    "DATA_ENTRENAMIENTO = './data/entrenamiento'\n",
    "DATA_VALIDACION = './data/validacion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros\n",
    "\n",
    "EPOCAS = 20                 # Numero de veces que iteraremos en el set de datos\n",
    "LONGITUD, ALTURA = 100,100  # Dimensiones de la imagenes a procesar\n",
    "BATCH_SIZE = 32             # Número de imágenes a procesar en cada iteración\n",
    "PASOS = 90                  # Veces que se procesará los datos en una época\n",
    "PASOS_VALIDACION = 300      # A final de cada época se correrá esta cantidad\n",
    "FILTROS_CONV_1 = 32         # Número de filtros que hará en cada imagen en la primera convolucion\n",
    "FILTROS_CONV_2 = 64         # Número de filtros que hará en cada imagen en la segunda convolucion\n",
    "TAMANO_FILTRO_1 = (3,3)     # Tamaño del filtro que estaremos usando en la primera convolución\n",
    "TAMANO_FILTRO_2 = (2,2)     # Tamaño del filtro que estaremos usando en la segunda convolución\n",
    "TAMANO_POOL = (2,2)         # Tamaño del filtro que se usará en el MaxPooling\n",
    "CLASES = 3                  # Número de elementos a clasificar\n",
    "LR = 0.0005                 # Learning Rate: Qué tan grande son los ajustes de la red neural para buscar una solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 297 images belonging to 3 classes.\n",
      "Found 91 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Pre-procesamiento de imágenes\n",
    "\n",
    "entrenamiento_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,       # Reescala cada uno de nuestros píxeles en vez que tengan un rango de 1 a 255, tenga uno de 0 a 1\n",
    "    shear_range = 0.3,      # Genera imagenes inclinadas\n",
    "    zoom_range = 0.3,       # Genera imágenes con zoom, esto para que el algoritmo aprenda que puede aparecer secciones del elemento\n",
    "    horizontal_flip = True  # Genera imágenes invertidas\n",
    ")\n",
    "\n",
    "validacion_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255        # Reescala cada uno de nuestros píxeles en vez que tengan un rango de 1 a 255, tenga uno de 0 a 1\n",
    ")\n",
    "\n",
    "\n",
    "entrenamiento_generador = entrenamiento_datagen.flow_from_directory(\n",
    "    DATA_ENTRENAMIENTO,                 # Entrar al directorio de las imagtenes de entrenamiento\n",
    "    target_size = (ALTURA,LONGITUD),    # Analizará la imagen con un ancho y altura especificada\n",
    "    batch_size = BATCH_SIZE,            # Tamaño ya definido del batch\n",
    "    class_mode = 'categorical'          # El tipo de clasificacion que haremos es categorical\n",
    ")\n",
    "\n",
    "validacion_generador = validacion_datagen.flow_from_directory(\n",
    "    DATA_VALIDACION,                 # Entrar al directorio de las imagtenes de entrenamiento\n",
    "    target_size = (ALTURA,LONGITUD),    # Analizará la imagen con un ancho y altura especificada\n",
    "    batch_size = BATCH_SIZE,            # Tamaño ya definido del batch\n",
    "    class_mode = 'categorical'          # El tipo de clasificacion que haremos es categorical\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cuanr\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Crear la red CNN\n",
    "\n",
    "cnn = Sequential()\n",
    "\n",
    "# Primera convolución\n",
    "cnn.add(Convolution2D(FILTROS_CONV_1, TAMANO_FILTRO_1, padding=\"same\", input_shape=(LONGITUD,ALTURA,3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=TAMANO_POOL))\n",
    "\n",
    "# Segunda convolución\n",
    "cnn.add(Convolution2D(FILTROS_CONV_2, TAMANO_FILTRO_2, padding='same', activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=TAMANO_POOL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Flatten())                           # La imagen restante de las convoluciones, la volvemos unidimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(256, activation='relu'))       # 256 Neuronas en esta capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cuanr\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "keep_prob = 0.5\n",
    "cnn.add(Dropout(rate=1-keep_prob))                        # A cada paso se apaga el 50% de las neuronas a la capa densa, esto para evitar sobre-ajustar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(CLASES, activation='softmax')) # Esta capa solo va a tener 3 neuronas con una activación de SoftMax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss='categorical_crossentropy',                   # La función de pérdida sea categorical_crossentropy\n",
    "            optimizer=\"adam\", # Se utiliza el optimizador Adam con el learning rate ya especificado\n",
    "            metrics=['accuracy']                               # La métrica a optimizar es el % de qué tan bien está siendo entrenada la red neuronal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cuanr\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 2s 743ms/step - loss: 1.2198 - acc: 0.3297\n",
      "10/10 [==============================] - 19s 2s/step - loss: 2.6417 - acc: 0.3468 - val_loss: 1.2198 - val_acc: 0.3297\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 2s 617ms/step - loss: 0.8808 - acc: 0.6593\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.0623 - acc: 0.5152 - val_loss: 0.8808 - val_acc: 0.6593\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 2s 699ms/step - loss: 0.7060 - acc: 0.7253\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.8474 - acc: 0.6364 - val_loss: 0.7060 - val_acc: 0.7253\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 2s 562ms/step - loss: 0.6382 - acc: 0.7363\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.7888 - acc: 0.6667 - val_loss: 0.6382 - val_acc: 0.7363\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 2s 553ms/step - loss: 0.5643 - acc: 0.7802\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.6669 - acc: 0.7508 - val_loss: 0.5643 - val_acc: 0.7802\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 2s 718ms/step - loss: 0.6181 - acc: 0.7912\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.6059 - acc: 0.7778 - val_loss: 0.6181 - val_acc: 0.7912\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 2s 594ms/step - loss: 0.4651 - acc: 0.8242\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.5737 - acc: 0.7677 - val_loss: 0.4651 - val_acc: 0.8242\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 2s 817ms/step - loss: 0.3965 - acc: 0.8681\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.5337 - acc: 0.7946 - val_loss: 0.3965 - val_acc: 0.8681\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 2s 748ms/step - loss: 0.3691 - acc: 0.8462\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.4703 - acc: 0.8081 - val_loss: 0.3691 - val_acc: 0.8462\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 0.4142 - acc: 0.8132\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.4739 - acc: 0.8114 - val_loss: 0.4142 - val_acc: 0.8132\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 3s 984ms/step - loss: 0.2857 - acc: 0.8901\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.4250 - acc: 0.8350 - val_loss: 0.2857 - val_acc: 0.8901\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 2s 668ms/step - loss: 0.3282 - acc: 0.8791\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.4217 - acc: 0.8687 - val_loss: 0.3282 - val_acc: 0.8791\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 2s 707ms/step - loss: 0.3899 - acc: 0.8352\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.3275 - acc: 0.8923 - val_loss: 0.3899 - val_acc: 0.8352\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 2s 660ms/step - loss: 0.3119 - acc: 0.8791\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.3386 - acc: 0.8620 - val_loss: 0.3119 - val_acc: 0.8791\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 2s 677ms/step - loss: 0.2585 - acc: 0.9341\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.3351 - acc: 0.8653 - val_loss: 0.2585 - val_acc: 0.9341\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 3s 938ms/step - loss: 0.1837 - acc: 0.9451\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.3171 - acc: 0.8721 - val_loss: 0.1837 - val_acc: 0.9451\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 2s 674ms/step - loss: 0.1422 - acc: 0.9341\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.2510 - acc: 0.9057 - val_loss: 0.1422 - val_acc: 0.9341\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 2s 692ms/step - loss: 0.1707 - acc: 0.9231\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.2636 - acc: 0.9259 - val_loss: 0.1707 - val_acc: 0.9231\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 2s 669ms/step - loss: 0.1412 - acc: 0.9451\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.2391 - acc: 0.9158 - val_loss: 0.1412 - val_acc: 0.9451\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 2s 696ms/step - loss: 0.0974 - acc: 0.9780\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.2589 - acc: 0.9192 - val_loss: 0.0974 - val_acc: 0.9780\n"
     ]
    }
   ],
   "source": [
    "cnn.fit(                                    # Para entrenar\n",
    "    entrenamiento_generador,                # Usar las imagenes ya preprocesadas de entrenamiento\n",
    "    steps_per_epoch = PASOS,                # Determinar la cantidad de pasos que tendrá las épocas\n",
    "    epochs = EPOCAS,                        # Cantidad de épocas \n",
    "    validation_data = validacion_generador, # Usar las imagenes ya preprocesadas de validación\n",
    "    validation_steps = PASOS_VALIDACION     # Qué tantos pasos realizar de validación en cada época\n",
    ")\n",
    "\n",
    "DIR_MODEL = './modelo/'\n",
    "\n",
    "if not os.path.exists(DIR_MODEL):  # Si no existe la carpeta modelo, la crea\n",
    "    os.mkdir(dir)\n",
    "\n",
    "cnn.save('./modelo/modelo.h5')          # Guarda la estructura del modelo\n",
    "cnn.save_weights('./modelo/pesos.h5')   # Guarda los valores de los pesos del modelo ya entrenado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
